import streamlit as st
import pandas as pd
from notion_client import Client
import google.generativeai as genai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼æ©Ÿèƒ½ ---
def check_password():
    try:
        correct_password = st.secrets["APP_PASSWORD"]
    except FileNotFoundError:
        st.error("ã‚¨ãƒ©ãƒ¼: .streamlit/secrets.toml ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    except KeyError:
        st.error("ã‚¨ãƒ©ãƒ¼: secrets.toml ã« APP_PASSWORD ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")

    if not password:
        st.stop()

    if password == correct_password:
        return True
    else:
        st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")
        st.stop()

# --- ãƒ¡ã‚¤ãƒ³ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---
def main_app():
    st.title("éƒ¨ç½²å†…ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œç´¢AI ğŸš€")

    NOTION_API_KEY = st.secrets["NOTION_API_KEY"]
    NOTION_DATABASE_ID = st.secrets["NOTION_DATABASE_ID"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]

    @st.cache_data(ttl=600)
    def get_prompts_from_notion():
        notion = Client(auth=NOTION_API_KEY)
        results = notion.databases.query(database_id=NOTION_DATABASE_ID).get("results")
        prompts_data = []
        for page in results:
            properties = page.get("properties", {})
            title = properties.get("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå", {}).get("title", [{}])[0].get("text", {}).get("content", "")
            keywords_list = [tag.get("name", "") for tag in properties.get("é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", {}).get("multi_select", [])]
            keywords = " ".join(keywords_list)
            page_content = ""
            try:
                blocks = notion.blocks.children.list(block_id=page["id"]).get("results")
                for block in blocks:
                    if block["type"] == "paragraph":
                        page_content += "".join([text["plain_text"] for text in block["paragraph"]["rich_text"]])
            except Exception:
                pass
            search_text = f"{title} {keywords} {page_content}"
            prompts_data.append({
                "title": title,
                "full_text": f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå: {title}\n\n---\n\n{page_content}",
                "search_text": search_text
            })
        return pd.DataFrame(prompts_data)

    def generate_answer_with_gemini(query, relevant_prompts):
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        if relevant_prompts.empty:
            return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€é–¢é€£ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        context = "\n\n".join(relevant_prompts['full_text'].tolist())
        prompt_for_gemini = f"""
        ã‚ãªãŸã¯ã€ç¤¾å†…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…±æœ‰ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
        ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã‚’åŸºã«ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æœ€ã‚‚åˆã†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        {query}
        # å‚è€ƒæƒ…å ±
        {context}
        # ã‚ãªãŸã®å›ç­”
        ä¸Šè¨˜ã®å‚è€ƒæƒ…å ±ã‚’è¸ã¾ãˆã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’1ã¤é¸ã³ã€ãªãœè‰¯ã„ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        ãã®å¾Œã€é¸ã‚“ã ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¨æ–‡ã‚’ã€ä»¥ä¸‹ã®å½¢å¼ã§å¿…ãšæç¤ºã—ã¦ãã ã•ã„ã€‚
        ---
        ### ææ¡ˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼š[ã“ã“ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå]
        ```
        [ã“ã“ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬æ–‡]
        ```
        """
        response = model.generate_content(prompt_for_gemini)
        return response.text

    try:
        df_prompts = get_prompts_from_notion()
        if not df_prompts.empty:
            vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 3))
            tfidf_matrix = vectorizer.fit_transform(df_prompts['search_text'])
    except Exception as e:
        st.error(f"Notionãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    user_query = st.text_input("ã©ã®ã‚ˆã†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãŠæ¢ã—ã§ã™ã‹ï¼Ÿ")

    if st.button("æ¤œç´¢"):
        if user_query:
            with st.spinner("ğŸ¤– AIãŒæ¤œç´¢ãƒ»å›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
                query_tfidf = vectorizer.transform([user_query])
                cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()
                relevant_indices = [i for i, score in enumerate(cosine_similarities) if score > 0.1]
                sorted_indices = sorted(relevant_indices, key=lambda i: cosine_similarities[i], reverse=True)
                top_indices = sorted_indices[:3]
                relevant_docs = df_prompts.iloc[top_indices]
                answer = generate_answer_with_gemini(user_query, relevant_docs)
                st.markdown("---")
                st.markdown("### ğŸ’¡ AIã‹ã‚‰ã®ææ¡ˆ")
                st.markdown(answer)
        else:
            st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# --- ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å®Ÿè¡Œé–‹å§‹ç‚¹ ---
if check_password():
    main_app()